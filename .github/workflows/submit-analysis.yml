name: Submit Template Analysis

on:
  repository_dispatch:
    types: [template-analysis-completed]

# Required permissions for the workflow
permissions:
  contents: write  # Needed to write to repository files
  pull-requests: write  # Needed to create pull requests

jobs:
  submit-analysis:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci
      
      - name: Debug payload
        run: |
          echo "Received repository dispatch event"
          echo "Repository URL: ${{ github.event.client_payload.repoUrl }}"
          echo "Rule Set: ${{ github.event.client_payload.ruleSet }}"
          echo "Username: ${{ github.event.client_payload.username }}"
          echo "Timestamp: ${{ github.event.client_payload.timestamp }}"
          echo "Upstream: ${{ github.event.client_payload.upstream }}"
          echo "Origin Upstream: ${{ github.event.client_payload.originUpstream }}"
          
      - name: Process analysis result
        id: process
        uses: ./
        with:
          repo-url: ${{ github.event.client_payload.repoUrl }}

          rule-set: ${{ github.event.client_payload.ruleSet }}
          username: ${{ github.event.client_payload.username }}
          timestamp: ${{ github.event.client_payload.timestamp }}
          analysis-data: ${{ toJSON(github.event.client_payload.analysisData) }}
          # Prefer originUpstream but accept upstream for backward-compat
          origin-upstream: ${{ github.event.client_payload.originUpstream || github.event.client_payload.upstream }}
          upstream: ${{ github.event.client_payload.upstream }}

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "[TD:BOT]: update template analysis for ${{ github.event.client_payload.repoUrl }}"
          title: "[TD:BOT]: add template analysis for ${{ github.event.client_payload.repoUrl }}"
          body: |
            This PR adds a new template analysis result, performed by Template Doctor:
            
            - Repository: ${{ github.event.client_payload.repoUrl }}
            - Ruleset: ${{ github.event.client_payload.ruleSet }}
            - Scanned by: ${{ github.event.client_payload.username }}
            - Date: ${{ github.event.client_payload.timestamp }}
            
            Compliance: ${{ fromJSON(steps.process.outputs.template-data).compliance.percentage }}% 
            (${{ fromJSON(steps.process.outputs.template-data).compliance.passed }} passed, ${{ fromJSON(steps.process.outputs.template-data).compliance.issues }} issues)
          branch: template-analysis-${{ github.run_id }}
          delete-branch: true
          base: main

      - name: Generate dynamic scan meta file & retention prune
        run: |
          set -euo pipefail
          REPO_URL='${{ github.event.client_payload.repoUrl }}'
          TS='${{ github.event.client_payload.timestamp }}'
          USERNAME='${{ github.event.client_payload.username }}'
          RULE_SET='${{ github.event.client_payload.ruleSet }}'
          COLLECTION='${{ github.event.client_payload.archiveCollection || vars.TD_ARCHIVE_COLLECTION || vars.TD_COLLECTION || 'aigallery' }}'
          TEMPLATE_DATA='${{ steps.process.outputs.template-data }}'
          if [ -z "$TEMPLATE_DATA" ]; then echo 'Missing template-data output'; exit 1; fi
          DASHBOARD_PATH=$(echo "$TEMPLATE_DATA" | jq -r '.dashboardPath // .dashboard_path // empty')
          DATA_PATH=$(echo "$TEMPLATE_DATA" | jq -r '.dataPath // .data_path // empty')
          if [ -z "$DASHBOARD_PATH" ] || [ -z "$DATA_PATH" ]; then
            echo 'dashboardPath/dataPath not exposed by action output; attempting to infer.'
            # Fallback: locate newest *-dashboard.html in results
            DASHBOARD_PATH=$(ls -1 packages/app/results/*/*-dashboard.html | sort -r | head -n1 | awk -F/ '{print $(NF)}') || true
            DATA_PATH=$(echo "$DASHBOARD_PATH" | sed 's/-dashboard.html/-data.js/')
          fi
          REPO_SLUG=$(echo "$REPO_URL" | awk -F/ '{print $(NF-1)"-"$NF}' | sed 's/.git$//')
          TARGET_DIR="packages/app/results/${REPO_SLUG}"
          if [ ! -d "$TARGET_DIR" ]; then echo "Target results dir $TARGET_DIR not found"; exit 1; fi
          RELATIVE_PATH="${REPO_SLUG}/${DASHBOARD_PATH}"
          META_FILE="$TARGET_DIR/scan-meta-${TS}.js"
          echo "Writing meta file $META_FILE"
          COMPLIANCE=$(echo "$TEMPLATE_DATA" | jq -c '.compliance // {percentage:0,issues:0,passed:0}')
          cat > "$META_FILE" <<EOF
window.__TD_DYNAMIC_RESULTS = window.__TD_DYNAMIC_RESULTS || [];
window.__TD_DYNAMIC_RESULTS.push({
  timestamp: $(printf %s "$TS" | jq -R .),
  dashboardPath: $(printf %s "$DASHBOARD_PATH" | jq -R .),
  dataPath: $(printf %s "$DATA_PATH" | jq -R .),
  repoUrl: $(printf %s "$REPO_URL" | jq -R .),
  collection: $(printf %s "$COLLECTION" | jq -R .),
  ruleSet: $(printf %s "$RULE_SET" | jq -R .),
  compliance: ${COMPLIANCE},
  scannedBy: [$(printf %s "$USERNAME" | jq -R .)],
  relativePath: $(printf %s "$RELATIVE_PATH" | jq -R .)
});
EOF

          # Retention: keep only latest 12 meta files per repo
          MAX=12
          COUNT=$(ls -1 $TARGET_DIR/scan-meta-*.js 2>/dev/null | wc -l || echo 0)
          if [ "$COUNT" -gt "$MAX" ]; then
            echo "Pruning old meta files (count=$COUNT > $MAX)"
            ls -1t $TARGET_DIR/scan-meta-*.js | tail -n +$((MAX+1)) | xargs -r git rm -f
          fi

          git add "$META_FILE" || true
          # Ensure meta-validator is tracked (idempotent)
          git add packages/app/results/meta-validator.js || true

      - name: PR Creation Status
        if: steps.process.outcome == 'success'
        run: |
          echo "Pull request creation complete"
          echo "See the Pull requests tab for the new PR"
          
      - name: PR Creation Error
        if: steps.process.outcome != 'success'
        run: |
          echo "⚠️ Error creating pull request!"
          echo "Check action logs for details"

      - name: Archive to central (if enabled)
        if: ${{ github.event.client_payload.archiveEnabled == true || github.event.client_payload.archiveEnabled == 'true' }}
        env:
          API_BASE: ${{ vars.TD_API_BASE || secrets.TD_API_BASE }}
          PAYLOAD_REPO_URL: ${{ github.event.client_payload.repoUrl }}
          PAYLOAD_RULE_SET: ${{ github.event.client_payload.ruleSet }}
          PAYLOAD_USERNAME: ${{ github.event.client_payload.username }}
          PAYLOAD_TIMESTAMP: ${{ github.event.client_payload.timestamp }}
          PAYLOAD_COLLECTION: ${{ github.event.client_payload.archiveCollection || vars.TD_ARCHIVE_COLLECTION || vars.TD_COLLECTION || 'aigallery' }}
          # Extract only the compliance object as JSON to avoid large env JSON parsing issues
          COMPLIANCE_JSON: ${{ toJSON(fromJSON(steps.process.outputs.template-data).compliance) }}
        run: |
          if [ -z "$API_BASE" ]; then
            echo "Archive API base not configured; skipping." && exit 0
          fi

          # Normalize API base (strip any trailing slash)
          API_BASE="${API_BASE%/}"

          repoUrl="$PAYLOAD_REPO_URL"
          repoName=$(echo "$repoUrl" | awk -F/ '{print $(NF-1)"-"$NF}' | sed 's/.git$//')
          analysisId="${GITHUB_RUN_ID}"
          username="${PAYLOAD_USERNAME:-${GITHUB_ACTOR}}"
          timestamp="$PAYLOAD_TIMESTAMP"
          collection="$PAYLOAD_COLLECTION"

          # Use precomputed compliance JSON from env; coerce null to {}
          if [ "${COMPLIANCE_JSON}" = "null" ] || [ -z "${COMPLIANCE_JSON}" ]; then
            compliance='{}'
          else
            compliance="${COMPLIANCE_JSON}"
          fi
          ruleSet="$PAYLOAD_RULE_SET"
          meta=$(jq -n --arg ruleSet "$ruleSet" --argjson compliance "$compliance" '{ruleSet:$ruleSet, compliance:$compliance}')

          payload=$(jq -n \
            --arg collection "$collection" \
            --arg repoUrl "$repoUrl" \
            --arg repoName "$repoName" \
            --arg analysisId "$analysisId" \
            --arg username "$username" \
            --arg timestamp "$timestamp" \
            --argjson metadata "$meta" \
            '{collection:$collection, repoUrl:$repoUrl, repoName:$repoName, analysisId:$analysisId, username:$username, timestamp:$timestamp, metadata:$metadata}')

          echo "Calling archive function with collection=$collection repo=$repoName"
          # Call archive endpoint; treat 409 Conflict as non-fatal (already archived)
          HTTP_CODE=$(curl -sS -o response.txt -w "%{http_code}" -X POST "$API_BASE/archive-collection" \
            -H 'Content-Type: application/json' \
            -d "$payload")
          echo "Archive HTTP status: $HTTP_CODE"
          echo "Archive response body:" && cat response.txt || true
          if [ "$HTTP_CODE" = "409" ]; then
            echo "Archive already exists (409). Skipping without failing the job."
            exit 0
          fi
          if [ "$HTTP_CODE" -lt 200 ] || [ "$HTTP_CODE" -ge 300 ]; then
            echo "Archive request failed with status $HTTP_CODE" >&2
            exit 1
          fi
